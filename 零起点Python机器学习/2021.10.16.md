# 第6章 机器学习经典算法案例（上）
## 6.1线性回归

- Ridge：岭回归算法
- LASSO：最小绝对值收缩和选择算法，俗称套索算法
- MultiTaskLasso:多任务LASSO回归算法，
- ElasticNet:弹性网眼算法
## 6.2逻辑回归算法
又称逻辑回归分析，是一种广义的线性回归分析模型，常用于数据挖掘、疾病自动诊断、经济预测等领域。例如，探讨引发疾病的危险因素，并根据危险因素预测疾病发生的概率等。
函数接口：
```
LogisticRegression(penalty='12',dual=False,tol=0.0001,C=1.0,fit_intercept=True,intercept_scaling=1,class_weight=None,random_state=None,solver='liblinear',max_iter=100
,multi_class='ovr',verbose=0,warm_start=False,n_jobs=1)


```
## 6.3朴素贝叶斯算法
是一系列分类算法的总称，这类算法均以贝叶斯定理为基础，故称贝叶斯分类。几个相关函数：

- MultinomialNB([alpha,...]),多项式朴素贝叶斯算法，
- GaussianNB([priors])：高斯朴素贝叶斯算法。
## 6.4KNN邻近算法
又叫做K最近邻分类算法，是数据挖掘分类技术中最简单的方法之一。所谓K最近邻就是k个最近邻居的意思，即每个样本都可以用它最接近的k个邻居来代表。主要的机器学习算法函数如下：
KNeighborsClassifier:KNN邻近算法
NearestNeighbos:最近邻居算法
KNeighborsRegressor:K近邻回归算法
NearestCentroid:最近质心算法
LSHForest:局部敏感哈希森林算法，是最近邻搜索方法的代替，排序实现二进制搜索和32位定长数组和散列，使用Hash家族的随机投影方法，近似余弦距离。
## 6.5随机森林算法
是指利用多颗树对样本进行训练并预测的一种算法。是一个包含多个决策树的算法，并且其输出的类别是由个别树输出的类别的众数而定。机器学习算法函数如下：

- RandomForestClassifier:随机森林算法
- BaggingClassifier:Bagging袋装算法，相当于多个专家投票表决，对于多次测试，每个样本返回的是多次预测结果较多的那个，
- ExtraTreesClassifier:完全随机树算法
- Adaboost:迭代算法，其核心思想是针对同一个训练集，训练不同的分类器（弱分类器），然后把这些弱分类器集合起来，构成一个更强的最终分类器（强分类器）
- GradientBoostingClassifier:GBT梯度Boosting树算法
- GradientBoostingRegressor:梯度回归算法
- VotingClassifier:投票算法

